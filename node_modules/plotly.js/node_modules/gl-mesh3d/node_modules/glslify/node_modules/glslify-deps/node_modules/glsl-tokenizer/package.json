{
  "name": "glsl-tokenizer",
  "version": "2.1.2",
  "description": "r/w stream of glsl tokens",
  "main": "string.js",
  "directories": {
    "test": "test"
  },
  "authors": [
    "Hugh Kennedy <hughskennedy@gmail.com> (http://hughsk.io/)",
    "Mikola Lysenko <mikolalysenko@gmail.com> (http://0fps.net)",
    "Chris Dickinson <chris@neversaw.us> (http://neversaw.us)"
  ],
  "scripts": {
    "test": "node test/index.js | tap-spec"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/gl-modules/glsl-tokenizer.git"
  },
  "keywords": [
    "glsl",
    "tokenizer",
    "stream"
  ],
  "author": {
    "name": "Chris Dickinson",
    "email": "chris@neversaw.us"
  },
  "license": "MIT",
  "dependencies": {
    "through2": "^0.6.3"
  },
  "devDependencies": {
    "tap-spec": "^1.0.1",
    "tape": "^3.0.2"
  },
  "readme": "# glsl-tokenizer\n\nMaps GLSL string data into GLSL tokens, either synchronously or using a\nstreaming API.\n\n``` javascript\nvar tokenString = require('glsl-tokenizer/string')\nvar tokenStream = require('glsl-tokenizer/stream')\nvar fs = require('fs')\n\n// Synchronously:\nvar tokens = tokenString(fs.readFileSync('some.glsl'))\n\n// Streaming API:\nfs.createReadStream('some.glsl')\n  .pipe(tokenStream())\n  .on('data', function(token) {\n    console.log(token.data, token.position, token.type)\n  })\n```\n\n# API\n\n## tokens = require('glsl-tokenizer/string')(src, [opt])\n\nReturns an array of `tokens` given the GLSL source string `src`\n\nYou can specify `opt.version` string to use different keywords/builtins, such as `'300 es'` for WebGL2. Otherwise, will assume GLSL 100 (WebGL1).\n\n```js\nvar tokens = tokenizer(src, {\n  version: '300 es'\n})\n```\n\n## stream = require('glsl-tokenizer/stream')([opt])\n\nEmits 'data' events whenever a token is parsed with a token object as output.\n\nAs above, you can specify `opt.version`.\n\n# Tokens\n\n```javascript\n{ 'type': TOKEN_TYPE\n, 'data': \"string of constituent data\"\n, 'position': integer position within the GLSL source\n, 'line': line number within the GLSL source\n, 'column': column number within the GLSL source }\n```\n\nThe available token types are:\n\n* `block-comment`: `/* ... */`\n* `line-comment`: `// ... \\n`\n* `preprocessor`: `# ... \\n`\n* `operator`: Any operator. If it looks like punctuation, it's an operator.\n* `float`: Optionally suffixed with `f`\n* `ident`: User defined identifier.\n* `builtin`: Builtin function.\n* `eof`: Emitted on `end`; data will === `'(eof)'`.\n* `integer`\n* `whitespace`\n* `keyword`\n\n# License\n\nMIT, see [LICENSE.md](LICENSE.md) for further information.\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/gl-modules/glsl-tokenizer/issues"
  },
  "homepage": "https://github.com/gl-modules/glsl-tokenizer",
  "_id": "glsl-tokenizer@2.1.2",
  "dist": {
    "shasum": "f30f644a860f7db3cad5f7ab66d833c6c7a66a5f"
  },
  "_from": "glsl-tokenizer@^2.0.2",
  "_resolved": "https://registry.npmjs.org/glsl-tokenizer/-/glsl-tokenizer-2.1.2.tgz"
}
